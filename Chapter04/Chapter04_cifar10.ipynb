{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# This line allows mpl to run with no DISPLAY defined\n",
    "mpl.use('Agg')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Reshape, Flatten, LeakyReLU, Activation\n",
    "from keras.layers.convolutional import UpSampling2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras_adversarial.image_grid_callback import ImageGridCallback\n",
    "\n",
    "from keras_adversarial import AdversarialModel, simple_gan, gan_targets\n",
    "from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling\n",
    "from keras_adversarial.legacy import Dense, BatchNormalization, fit, l1l2, Convolution2D, AveragePooling2D\n",
    "import keras.backend as K\n",
    "from cifar10_utils import cifar10_data\n",
    "from image_utils import dim_ordering_fix, dim_ordering_unfix, dim_ordering_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_generator():\n",
    "    model = Sequential()\n",
    "    nch = 256\n",
    "    reg = lambda: l1l2(l1=1e-7, l2=1e-7)\n",
    "    h = 5\n",
    "    model.add(Dense(nch * 4 * 4, input_dim=100, W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0))\n",
    "    model.add(Reshape(dim_ordering_shape((nch, 4, 4))))\n",
    "    model.add(Convolution2D(int(nch / 2), h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0, axis=1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(int(nch / 2), h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0, axis=1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(int(nch / 4), h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0, axis=1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(3, h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model descriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_discriminator():\n",
    "    nch = 256\n",
    "    h = 5\n",
    "    reg = lambda: l1l2(l1=1e-7, l2=1e-7)\n",
    "\n",
    "    c1 = Convolution2D(int(nch / 4), h, h, border_mode='same', W_regularizer=reg(),\n",
    "                       input_shape=(32, 32, 3))\n",
    "                       # input_shape=dim_ordering_shape((32, 32, 3)))\n",
    "    c2 = Convolution2D(int(nch / 2), h, h, border_mode='same', W_regularizer=reg())\n",
    "    c3 = Convolution2D(nch, h, h, border_mode='same', W_regularizer=reg())\n",
    "    c4 = Convolution2D(1, h, h, border_mode='same', W_regularizer=reg())\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(c1)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(c2)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(c3)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(c4)\n",
    "    model.add(AveragePooling2D(pool_size=(4, 4), border_mode='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example_gan(adversarial_optimizer, path, opt_g, opt_d, nb_epoch, generator, discriminator, latent_dim,\n",
    "                targets=gan_targets, loss='binary_crossentropy'):\n",
    "    csvpath = os.path.join(path, \"history.csv\")\n",
    "    if os.path.exists(csvpath):\n",
    "        print('Already exists: {}'.format(csvpath))\n",
    "        return\n",
    "    \n",
    "    print(\"Training: {}\".format(csvpath))\n",
    "    generator.summary()\n",
    "    discriminator.summary()\n",
    "    gan = simple_gan(generator=generator,\n",
    "                     discriminator=discriminator,\n",
    "                     latent_sampling=normal_latent_sampling((latent_dim, ))\n",
    "                    )\n",
    "    model = AdversarialModel(base_model=gan,\n",
    "                             player_params=[generator.trainable_weights, discriminator.trainable_weights],\n",
    "                             player_names=[\"generator\", \"descriminator\"]\n",
    "                         )\n",
    "    model.adversarial_compile(adversarial_optimizer=adversarial_optimizer,\n",
    "                              player_optimizers=[opt_g, opt_d], loss=loss)\n",
    "    \n",
    "    zsample = np.random.normal(size=(10 * 10, latent_dim))\n",
    "    \n",
    "    def generator_sampler():\n",
    "        xpred = dim_ordering_unfix(generator.predict(zsamples)).transpose((0, 2, 3, 1))\n",
    "        return xpred.reshape((10, 10) + xpred.shape[1:])\n",
    "    \n",
    "    generator_cb = ImageGridCallback(os.path.join(path, \"epoch-{:03d}.png\"), generator_sampler, cmap=None)\n",
    "    \n",
    "    xtrain, xtest = cifar10_data()\n",
    "    print(xtrain.shape)\n",
    "    # xtrain = dim_ordering_fix(xtrain)\n",
    "    # xtest = dim_ordering_fix(xtest)\n",
    "    y = targets(xtrain.shape[0])\n",
    "    ytest = targets(xtest.shape[0])\n",
    "    callbacks = [generator_cb]\n",
    "    if K.backend() == \"tensorflow\":\n",
    "        callbacks.append(TensorBoard(log_dir=os.path.join(path, 'logs'), histogram_freq=0, \n",
    "                                     write_graph=True, write_images=True))\n",
    "    history = fit(model, x=xtrain, y=y, validation_data=(xtest, ytest),\n",
    "                 batch_size=32)\n",
    "    \n",
    "    df = pd.DataFarme(history.history)\n",
    "    df.to_csv(csvpath)\n",
    "    \n",
    "    generator.save(os.path.join(path, 'generator.h5'))\n",
    "    descriminator.save(os.path.join(path, 'descriminator.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "generator = model_generator()\n",
    "discriminator = model_discriminator()\n",
    "example_gan(AdversarialOptimizerSimultaneous(), \"./output/gan-cifar10\",\n",
    "            opt_g=Adam(1e-4, decay=1e-5),\n",
    "            opt_d=Adam(1e-3, decay=1e-5),\n",
    "            nb_epoch=100,\n",
    "            generator=generator,\n",
    "            discriminator=discriminator,\n",
    "            latent_dim=latent_dim\n",
    "           )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}